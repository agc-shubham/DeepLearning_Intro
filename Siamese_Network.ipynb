{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9eaef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # input channels = 1 for grayscale\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 128x128\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 64x64\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))  # output: (batch, 128, 1, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x.view(x.size(0), -1)  # Flatten to (batch, 128)\n",
    "\n",
    "class SiameseClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 1),  # binary output\n",
    "        )\n",
    "\n",
    "    def forward(self, kernel_img, input_img):\n",
    "        f1 = self.feature_extractor(kernel_img)  # shape: (B, 128)\n",
    "        f2 = self.feature_extractor(input_img)\n",
    "\n",
    "        combined = torch.cat([f1, f2], dim=1)  # shape: (B, 256)\n",
    "        out = self.classifier(combined)\n",
    "        return torch.sigmoid(out).squeeze(1)  # shape: (B,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85567bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, batch, criterion, optimizer):\n",
    "    kernel_img, input_img, label = batch  # each shape: (B, 1, 256, 256)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(kernel_img, input_img)\n",
    "    loss = criterion(output, label.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d583bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class WaferPairDataset(Dataset):\n",
    "    def __init__(self, kernel_paths, input_paths, labels, image_size=256):\n",
    "        self.kernel_paths = kernel_paths\n",
    "        self.input_paths = input_paths\n",
    "        self.labels = labels\n",
    "\n",
    "        # Define transforms\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor(),  # Converts to (C, H, W) in [0, 1]\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1]\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        kernel_img = Image.open(self.kernel_paths[idx])\n",
    "        input_img = Image.open(self.input_paths[idx])\n",
    "\n",
    "        kernel_img = self.transform(kernel_img)\n",
    "        input_img = self.transform(input_img)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "        return kernel_img, input_img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df634229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Example lists (replace with your actual paths and labels)\n",
    "kernel_paths = ['/path/to/kernel1.png', '/path/to/kernel2.png', ...]\n",
    "input_paths = ['/path/to/input1.png', '/path/to/input2.png', ...]\n",
    "labels = [1, 0, ...]  # 1 = pass, 0 = fail\n",
    "\n",
    "# Create dataset\n",
    "dataset = WaferPairDataset(kernel_paths, input_paths, labels)\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce68d95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def train(model, train_loader, val_loader, num_epochs, optimizer, criterion, device, save_path='best_model.pt'):\n",
    "    model = model.to(device)\n",
    "    best_f1 = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        for kernel, input_img, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "            kernel = kernel.to(device)\n",
    "            input_img = input_img.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(kernel, input_img)  # shape: (B,)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "            all_preds.extend((outputs > 0.5).int().cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_acc = accuracy_score(all_labels, all_preds)\n",
    "        train_f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "        # Validation\n",
    "        val_loss, val_acc, val_f1 = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1}:\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | F1: {train_f1:.4f}\")\n",
    "        print(f\"Val   Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"âœ… Best model saved with F1: {best_f1:.4f}\")\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for kernel, input_img, labels in loader:\n",
    "            kernel = kernel.to(device)\n",
    "            input_img = input_img.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(kernel, input_img)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            all_preds.extend((outputs > 0.5).int().cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    return avg_loss, acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1424b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Assuming dataset is already created\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "# Model, loss, optimizer\n",
    "model = SiameseClassifier()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Train\n",
    "train(model, train_loader, val_loader, num_epochs=20, optimizer=optimizer, criterion=criterion, device=device)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
