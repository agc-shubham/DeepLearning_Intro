{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2c8ebe0",
   "metadata": {},
   "source": [
    "# Siamese Network for Wafer Pass/Fail Prediction\n",
    "This notebook builds and trains a Siamese neural network to predict wafer alignment success based on kernel and input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2109cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc012b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature Extractor ---\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x.view(x.size(0), -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d0905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Siamese Classifier ---\n",
    "class SiameseClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, kernel_img, input_img):\n",
    "        f1 = self.feature_extractor(kernel_img)\n",
    "        f2 = self.feature_extractor(input_img)\n",
    "        combined = torch.cat([f1, f2], dim=1)\n",
    "        out = self.classifier(combined)\n",
    "        return torch.sigmoid(out).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f3d444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dataset ---\n",
    "class WaferPairDataset(Dataset):\n",
    "    def __init__(self, kernel_paths, input_paths, labels, image_size=256):\n",
    "        self.kernel_paths = kernel_paths\n",
    "        self.input_paths = input_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        kernel_img = Image.open(self.kernel_paths[idx])\n",
    "        input_img = Image.open(self.input_paths[idx])\n",
    "        kernel_img = self.transform(kernel_img)\n",
    "        input_img = self.transform(input_img)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return kernel_img, input_img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d1f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluation ---\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for kernel, input_img, labels in loader:\n",
    "            kernel = kernel.to(device)\n",
    "            input_img = input_img.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(kernel, input_img)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            all_preds.extend((outputs > 0.5).int().cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    return avg_loss, acc, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd50277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Loop ---\n",
    "def train(model, train_loader, val_loader, num_epochs, optimizer, scheduler, criterion, device, save_path='best_model.pt'):\n",
    "    model = model.to(device)\n",
    "    best_f1 = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_preds, all_labels = [], []\n",
    "        for kernel, input_img, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "            kernel = kernel.to(device)\n",
    "            input_img = input_img.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(kernel, input_img)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "            all_preds.extend((outputs > 0.5).int().cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_acc = accuracy_score(all_labels, all_preds)\n",
    "        train_f1 = f1_score(all_labels, all_preds)\n",
    "        val_loss, val_acc, val_f1 = evaluate(model, val_loader, criterion, device)\n",
    "        print(f\"\\nEpoch {epoch+1}:\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | F1: {train_f1:.4f}\")\n",
    "        print(f\"Val   Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f}\")\n",
    "        scheduler.step(val_loss)\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"âœ… Best model saved with F1: {best_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9b4b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup Example ---\n",
    "# Replace with actual file paths and labels\n",
    "kernel_paths = ['/path/to/kernel1.png', '/path/to/kernel2.png']\n",
    "input_paths = ['/path/to/input1.png', '/path/to/input2.png']\n",
    "labels = [1, 0]  # 1 = pass, 0 = fail\n",
    "\n",
    "# Create dataset and data loaders\n",
    "dataset = WaferPairDataset(kernel_paths, input_paths, labels)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
    "\n",
    "# Initialize model, loss, optimizer\n",
    "model = SiameseClassifier()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Train\n",
    "train(model, train_loader, val_loader, num_epochs=10, optimizer=optimizer, scheduler=scheduler, criterion=criterion, device=device)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
